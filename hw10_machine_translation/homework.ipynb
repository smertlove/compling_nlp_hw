{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dba7c0d",
   "metadata": {},
   "source": [
    "# Домашнее задание № 10. Машинный перевод"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Yj7aripVIsbG",
   "metadata": {
    "id": "Yj7aripVIsbG"
   },
   "source": [
    "## Задание 1 (6 баллов + 2 доп балла).\n",
    "Нужно обучить трансформер на том же корпусе но в другую сторону - с русского на английский.\n",
    "Можно использовать как основу первый или второй способ реализации (с MultiheadAttention или с nn.Transformer). Подберите несколько тестовых примеров для проверки обучения на каждой эпохе. \n",
    "\n",
    "Параметры ниже точно работают в колабе и модель обучается достаточно быстро. Попробуйте их немного увеличить (batch size возможно придется наоборот уменьшить). Обучайте модель хотя бы 5 эпох, а желательно больше, чтобы тестовые примеры начали переводиться более менее адекватно. \n",
    "\n",
    "После обучения возьмите хотя бы 100 примером из тестовой части параллельного корпуса и переведите их. Оцените качество переводов с помощью метрики BLEU (пример использования ниже)\n",
    "Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
    "\n",
    "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [EOS] в текущем коде не сработает). \n",
    "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах! Функция с batch prediction должна работать быстрее, поэтому переведите всю тестовую выборку и оцените качество BLEU на всех данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f491f99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers.pre_tokenizers import Whitespace\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "from tokenizers import decoders\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
    "from collections import Counter\n",
    "\n",
    "from torchtune.modules import RotaryPositionalEmbeddings\n",
    "from torch.nn import Transformer\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfecc9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbf2ee68",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('./data/en-ru-train.ru').read().replace('\\xa0', ' ')\n",
    "f = open('./data/en-ru-train.ru', 'w')\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27435a1b",
   "metadata": {},
   "source": [
    "<s>Я честно пытался сделать нормально, переписать где-то имена переменных и пр, но постоянно возникала ошибка с тем, что я получал вывод из translate на уровне\n",
    "\"Привет\" > \"G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G G\"\n",
    "поэтому</s> Теперь модель должна заработать, но я всё равно обучу пару ru-en взяв полностью код из семинара и применив небольшой трюк.\n",
    "Он заключается в том, чтобы все имена переменных и весь код оставить в неизменном виде и поменять только именя файлов для тренировочных датасетов токенизаторов и модели. Таким образов в en-переменных окажутся токенизатор, сет, векторы, матрицы и пр, связанные с русским языком, а в ru-переменных -- с английским. Просто уже хочется перейти к интересной части домашки, а не заниматься переименовыванием переменных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1444e44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_sents = open('./data/en-ru-train.ru').read().splitlines()  #  <-- Трюк\n",
    "ru_sents = open('./data/en-ru-train.en').read().splitlines()  #  <-- Трюк"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439d0cee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "create new\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tokenizer_en = Tokenizer.from_file(\"./data/tokenizer_en\")\n",
    "    tokenizer_ru = Tokenizer.from_file(\"./data/tokenizer_ru\")\n",
    "    print(\"load existing\")\n",
    "except Exception:\n",
    "    tokenizer_en = Tokenizer(BPE())\n",
    "    tokenizer_en.pre_tokenizer = Whitespace()\n",
    "    trainer_en = BpeTrainer(special_tokens=[\"[PAD]\"], end_of_word_suffix='</w>')\n",
    "    tokenizer_en.train(\n",
    "        files=[\"./data/en-ru-train.ru\"],  #  <-- Трюк\n",
    "        trainer=trainer_en\n",
    "    )\n",
    "\n",
    "    tokenizer_ru = Tokenizer(BPE())\n",
    "    tokenizer_ru.pre_tokenizer = Whitespace()\n",
    "    trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix='</w>')\n",
    "    tokenizer_ru.train(\n",
    "        files=[\"./data/en-ru-train.en\"],  #  <-- Трюк\n",
    "        trainer=trainer_ru\n",
    "    )\n",
    "\n",
    "    tokenizer_en.decoder = decoders.BPEDecoder()\n",
    "    tokenizer_ru.decoder = decoders.BPEDecoder()\n",
    "\n",
    "    tokenizer_en.save('./data/tokenizer_en')\n",
    "    tokenizer_ru.save('./data/tokenizer_ru')\n",
    "    print(\"create new\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f10bc06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text, tokenizer, max_len, encoder=False):\n",
    "    if encoder:\n",
    "        return tokenizer.encode(text).ids[:max_len]\n",
    "    else:\n",
    "        return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[EOS]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e3ea37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# важно следить чтобы индекс паддинга совпадал в токенизаторе с value в pad_sequences\n",
    "# у нас это в любом случае ноль но лучше safe than sorry\n",
    "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
    "PAD_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c243d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_en, max_len_ru = 47, 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcffd51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en = [encode(t, tokenizer_en, max_len_en, encoder=True) for t in en_sents]\n",
    "X_ru = [encode(t, tokenizer_ru, max_len_ru) for t in ru_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b2d6aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_en), len(X_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78736097",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, texts_en, texts_ru):\n",
    "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
    "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
    "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, batch_first=True, padding_value=PAD_IDX)\n",
    "\n",
    "        self.length = len(texts_en)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        ids_en = self.texts_en[index]\n",
    "        ids_ru = self.texts_ru[index]\n",
    "\n",
    "        return ids_en, ids_ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8eb86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_en_train, X_en_valid, X_ru_train, X_ru_valid = train_test_split(X_en, X_ru, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c9dd5e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim)\n",
    "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim)\n",
    "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads, max_seq_len=128)\n",
    "\n",
    "        self.transformer = Transformer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            num_encoder_layers=num_layers,\n",
    "            num_decoder_layers=num_layers,\n",
    "            dim_feedforward=ff_dim,\n",
    "            dropout=dropout,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
    "\n",
    "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
    "\n",
    "        src_embedded = self.embedding_enc(src)\n",
    "        B,S,E = src_embedded.shape\n",
    "        src_embedded = self.positional_encoding(src_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
    "\n",
    "        tgt_embedded = self.embedding_dec(tgt)\n",
    "        B,S,E = tgt_embedded.shape\n",
    "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
    "\n",
    "\n",
    "        tgt_mask = (~torch.tril(torch.ones((S, S), dtype=torch.bool))).to(DEVICE)\n",
    "\n",
    "        encoder_output = self.transformer.encoder(\n",
    "            src_embedded,\n",
    "            src_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "\n",
    "        decoder_output = self.transformer.decoder(\n",
    "            tgt_embedded,\n",
    "            encoder_output,\n",
    "            tgt_mask=tgt_mask,\n",
    "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
    "            memory_key_padding_mask=src_key_padding_mask\n",
    "        )\n",
    "\n",
    "        output = self.output_layer(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87809664",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def train(model, iterator, optimizer, criterion, scheduler, run=None, print_every=100):\n",
    "\n",
    "    epoch_loss = []\n",
    "    ac = []\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "        texts_en = texts_en.to(DEVICE)\n",
    "        texts_ru = texts_ru.to(DEVICE)\n",
    "        texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
    "        texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
    "        src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
    "        tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
    "\n",
    "\n",
    "        logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
    "        optimizer.zero_grad()\n",
    "        B,S,C = logits.shape\n",
    "        loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        if not (i+1) % print_every:\n",
    "            print(f'Loss: {np.mean(epoch_loss)};')\n",
    "        if run is not None:\n",
    "            run.log({\"loss\": loss.item()})\n",
    "\n",
    "    return np.mean(epoch_loss)\n",
    "\n",
    "\n",
    "def evaluate(model, iterator, criterion, run=None):\n",
    "\n",
    "    epoch_loss = []\n",
    "    epoch_f1 = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (texts_en, texts_ru) in enumerate(iterator):\n",
    "            texts_en = texts_en.to(DEVICE)\n",
    "            texts_ru = texts_ru.to(DEVICE)\n",
    "            texts_ru_input = texts_ru[:,:-1].to(DEVICE)\n",
    "            texts_ru_out = texts_ru[:, 1:].to(DEVICE)\n",
    "            src_padding_mask = (texts_en == PAD_IDX).to(DEVICE)\n",
    "            tgt_padding_mask = (texts_ru_input == PAD_IDX).to(DEVICE)\n",
    "\n",
    "            logits = model(texts_en, texts_ru_input, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "            B,S,C = logits.shape\n",
    "            loss = loss_fn(logits.reshape(B*S, C), texts_ru_out.reshape(B*S))\n",
    "            epoch_loss.append(loss.item())\n",
    "            if run is not None:\n",
    "                run.log({\"val_loss\": loss.item()})\n",
    "\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f841373d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def translate(text):\n",
    "\n",
    "\n",
    "    input_ids = tokenizer_en.encode(text).ids[:max_len_en]\n",
    "    output_ids = [tokenizer_ru.token_to_id('[BOS]')]\n",
    "\n",
    "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)], batch_first=True).to(DEVICE)\n",
    "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
    "\n",
    "    src_padding_mask = (input_ids_pad == PAD_IDX).to(DEVICE)\n",
    "    tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
    "\n",
    "    logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
    "\n",
    "    pred = logits.argmax(2).item()\n",
    "\n",
    "    while pred not in [tokenizer_ru.token_to_id('[EOS]'), tokenizer_ru.token_to_id('[PAD]')] and len(output_ids) < 100:\n",
    "        output_ids.append(pred)\n",
    "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
    "        tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
    "\n",
    "        logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
    "        pred = logits.argmax(2).view(-1)[-1].item()\n",
    "\n",
    "    return tokenizer_ru.decoder.decode([tokenizer_ru.id_to_token(i) for i in output_ids[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c97e741",
   "metadata": {},
   "outputs": [],
   "source": [
    "# попробуйте поставить параметры поменьше если в колабе обучается слишком долго!\n",
    "vocab_size_enc = tokenizer_en.get_vocab_size()\n",
    "vocab_size_dec = tokenizer_ru.get_vocab_size()\n",
    "embed_dim = 256 # еще называется D_MODEL\n",
    "num_heads = 8\n",
    "ff_dim = embed_dim*4 # еще называется D_FF\n",
    "num_layers = 4 # количество слоев\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# model = TransformerEncoderDecoder(vocab_size_enc,vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers)\n",
    "model = torch.load(\"./model\", weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e5e5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = Dataset(X_en_train, X_ru_train)\n",
    "training_generator = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, )\n",
    "\n",
    "valid_set = Dataset(X_en_valid, X_ru_valid)\n",
    "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "184c3261",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ed4196fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x749820ae3550>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_model = torch.nn.Linear(2, 1)\n",
    "fake_optimizer = torch.optim.AdamW(fake_model.parameters(), lr=0.0001)\n",
    "fake_scheduler = torch.optim.lr_scheduler.OneCycleLR(fake_optimizer, max_lr=0.001, pct_start=0.05,\n",
    "                                                steps_per_epoch=50, epochs=20)\n",
    "lrs = []\n",
    "\n",
    "for i in range(1000):\n",
    "    fake_optimizer.step()\n",
    "    lrs.append(fake_optimizer.param_groups[0][\"lr\"])\n",
    "    fake_scheduler.step()\n",
    "\n",
    "plt.plot(lrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66e9d04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(DEVICE)\n",
    "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "NUM_EPOCHS = 20\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, pct_start=0.05,\n",
    "                                                steps_per_epoch=len(training_generator), epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6791b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4360236b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.949082534313202;\n",
      "Loss: 3.9336834275722503;\n",
      "Loss: 3.9300958863894144;\n",
      "Loss: 3.9239002269506456;\n",
      "Loss: 3.9194034538269045;\n",
      "Loss: 3.915216954151789;\n",
      "Loss: 3.9115869528906684;\n",
      "Loss: 3.911065395474434;\n",
      "Loss: 3.907218619717492;\n",
      "Loss: 3.9068280210494994;\n",
      "Loss: 3.904889338883487;\n",
      "Loss: 3.9033943806091944;\n",
      "Loss: 3.900322900368617;\n",
      "Loss: 3.896794419458934;\n",
      "Loss: 3.891954797744751;\n",
      "Loss: 3.8883381105959414;\n",
      "Loss: 3.8856318900164437;\n",
      "Loss: 3.8836819529533386;\n",
      "Loss: 3.881686609795219;\n",
      "Loss: 3.8791058444976807;\n",
      "Loss: 3.8769428009078615;\n",
      "Loss: 3.874616386456923;\n",
      "Loss: 3.870551896095276;\n",
      "Loss: 3.8671520191431044;\n",
      "Loss: 3.8651726276397707;\n",
      "Loss: 3.8622736778626074;\n",
      "Loss: 3.8593919431721724;\n",
      "Loss: 3.8565168835435597;\n",
      "Loss: 3.8545824130650224;\n",
      "Loss: 3.851439120451609;\n",
      "Loss: 3.8484368844186108;\n",
      "Loss: 3.8454179868847134;\n",
      "Loss: 3.8424059492891485;\n",
      "Loss: 3.839518458001754;\n",
      "Loss: 3.8364578933034625;\n",
      "Loss: 3.834244335691134;\n",
      "Loss: 3.832266693372984;\n",
      "Loss: 3.8298862188113363;\n",
      "Loss: 3.8277087613252494;\n",
      "Loss: 3.825045092999935;\n",
      "Loss: 3.8224432135209803;\n",
      "Loss: 3.820023143745604;\n",
      "Loss: 3.8170518829656204;\n",
      "Loss: 3.814377285621383;\n",
      "Loss: 3.8114849544101292;\n",
      "Loss: 3.8092242454964182;\n",
      "Loss: 3.806616857102577;\n",
      "Loss: 3.8039901759227117;\n",
      "Loss: 3.801321199524159;\n",
      "Loss: 3.7987027143001555;\n",
      "Loss: 3.79596055764778;\n",
      "Loss: 3.7934983691343893;\n",
      "Loss: 3.791151742260411;\n",
      "Loss: 3.7881861550278133;\n",
      "Loss: 3.7852606007836083;\n",
      "Loss: 3.7826936868258887;\n",
      "Loss: 3.780332415187568;\n",
      "Loss: 3.777935582070515;\n",
      "Loss: 3.7755400069689347;\n",
      "Loss: 3.7729717219670613;\n",
      "Loss: 3.7709360043338087;\n",
      "Loss: 3.7686125964503137;\n",
      "Loss: 3.766589464762854;\n",
      "Loss: 3.7644677375257016;\n",
      "Loss: 3.761681135947888;\n",
      "Loss: 3.759980038693457;\n",
      "Loss: 3.757161330892079;\n",
      "Loss: 3.754673610469874;\n",
      "Loss: 3.7519599888981254;\n",
      "Loss: 3.7499067366804395;\n",
      "Loss: 3.747972400591407;\n",
      "Loss: 3.745395119090875;\n",
      "Loss: 3.743253140384204;\n",
      "Loss: 3.741227422114965;\n",
      "Loss: 3.7388930686314903;\n",
      "Loss: 3.7367624151392986;\n",
      "Loss: 3.734521934119138;\n",
      "Loss: 3.732192834065511;\n",
      "Loss: 3.7299266579784924;\n",
      "Loss: 3.7277534854710104;\n",
      "Loss: 3.7255476161874372;\n",
      "Loss: 3.723323187973441;\n",
      "Loss: 3.7209207119999164;\n",
      "Loss: 3.7188215972696033;\n",
      "Loss: 3.7168120877883015;\n",
      "Loss: 3.714725243296734;\n",
      "Loss: 3.7125173189996303;\n",
      "Loss: 3.710049873942679;\n",
      "Loss: 3.707789879166678;\n",
      "Loss: 3.705409871419271;\n",
      "Loss: 3.7034906525664275;\n",
      "Loss: 3.701324853301048;\n",
      "Loss: 3.6989451312249706;\n",
      "Loss: 3.696767253419186;\n",
      "Loss: 3.6944740974526655;\n",
      "First epoch - 3.372843288898468, saving model..\n",
      "Epoch: 1, Train loss: 3.694, Val loss: 3.373,            Epoch time=1170.050s\n",
      "Hey !\n",
      "How ' s your business ?\n",
      "How ' s the kids ?\n",
      "You ' re still looking for those guys , huh ?\n",
      "Loss: 3.352384886741638;\n",
      "Loss: 3.377538403272629;\n",
      "Loss: 3.3739366245269777;\n",
      "Loss: 3.3809338986873625;\n",
      "Loss: 3.375786662578583;\n",
      "Loss: 3.3743927176793416;\n",
      "Loss: 3.378048824923379;\n",
      "Loss: 3.3803492426872253;\n",
      "Loss: 3.3806107968754238;\n",
      "Loss: 3.379668304204941;\n",
      "Loss: 3.3774262788079;\n",
      "Loss: 3.3770664797226586;\n",
      "Loss: 3.3749958905806907;\n",
      "Loss: 3.375688225882394;\n",
      "Loss: 3.374785448710124;\n",
      "Loss: 3.375317856222391;\n",
      "Loss: 3.3742066180004793;\n",
      "Loss: 3.3729317887624104;\n",
      "Loss: 3.372536161196859;\n",
      "Loss: 3.3704881345033644;\n",
      "Loss: 3.370677710828327;\n",
      "Loss: 3.369713147878647;\n",
      "Loss: 3.3694657542394557;\n",
      "Loss: 3.3694365220268567;\n",
      "Loss: 3.3687826461791994;\n",
      "Loss: 3.367795753845802;\n",
      "Loss: 3.3673633098602296;\n",
      "Loss: 3.3670350036450793;\n",
      "Loss: 3.3659977919479895;\n",
      "Loss: 3.3657675797144573;\n",
      "Loss: 3.36547955559146;\n",
      "Loss: 3.3643054187297823;\n",
      "Loss: 3.363662443666747;\n",
      "Loss: 3.3641539014087005;\n",
      "Loss: 3.3634892069952826;\n",
      "Loss: 3.3629708935817084;\n",
      "Loss: 3.3624375901351105;\n",
      "Loss: 3.3614049703823894;\n",
      "Loss: 3.360746029156905;\n",
      "Loss: 3.3601083560585976;\n",
      "Loss: 3.359258831361445;\n",
      "Loss: 3.3579831384477163;\n",
      "Loss: 3.3571866972501887;\n",
      "Loss: 3.356062251546166;\n",
      "Loss: 3.354449571503533;\n",
      "Loss: 3.3536905542663904;\n",
      "Loss: 3.3524247749815594;\n",
      "Loss: 3.351333048890034;\n",
      "Loss: 3.3509344135985084;\n",
      "Loss: 3.350160437870026;\n",
      "Loss: 3.348980936022366;\n",
      "Loss: 3.347464415522722;\n",
      "Loss: 3.346729788330366;\n",
      "Loss: 3.3457028831817484;\n",
      "Loss: 3.344378718549555;\n",
      "Loss: 3.343678504100868;\n",
      "Loss: 3.3428335167232315;\n",
      "Loss: 3.3419285159686516;\n",
      "Loss: 3.3412189870365596;\n",
      "Loss: 3.3400142702261606;\n",
      "Loss: 3.3385005744558867;\n",
      "Loss: 3.337401682753717;\n",
      "Loss: 3.336213525552598;\n",
      "Loss: 3.33555127274245;\n",
      "Loss: 3.334431594995352;\n",
      "Loss: 3.3331869392322773;\n",
      "Loss: 3.3320522632527707;\n",
      "Loss: 3.330975123713998;\n",
      "Loss: 3.330346105617026;\n",
      "Loss: 3.329180339200156;\n",
      "Loss: 3.3282825297369083;\n",
      "Loss: 3.3268421982394325;\n",
      "Loss: 3.325586902278743;\n",
      "Loss: 3.3247486062307616;\n",
      "Loss: 3.3236473386764525;\n",
      "Loss: 3.322618584225052;\n",
      "Loss: 3.3216898433573836;\n",
      "Loss: 3.3202854953362393;\n",
      "Loss: 3.3189610168601895;\n",
      "Loss: 3.317996403336525;\n",
      "Loss: 3.3168538910371286;\n",
      "Loss: 3.3157150828547595;\n",
      "Loss: 3.314569318754127;\n",
      "Loss: 3.3133068145172935;\n",
      "Loss: 3.3119008423861334;\n",
      "Loss: 3.3106847377710564;\n",
      "Loss: 3.3094203628342727;\n",
      "Loss: 3.3080483584241436;\n",
      "Loss: 3.3069838359382717;\n",
      "Loss: 3.305959596289529;\n",
      "Loss: 3.304850707316137;\n",
      "Loss: 3.303933318620143;\n",
      "Loss: 3.3032865430462746;\n",
      "Loss: 3.3020573257385415;\n",
      "Loss: 3.3009852179728054;\n",
      "Improved from 3.372843288898468 to 3.080909373283386, saving model..\n",
      "Epoch: 2, Train loss: 3.301, Val loss: 3.081,            Epoch time=1042.171s\n",
      "Hey !\n",
      "How are you doing ?\n",
      "How ' s the wife like children ?\n",
      "You ' re still a nice one of these guys , right ?\n",
      "Loss: 3.0675089716911317;\n",
      "Loss: 3.070097107887268;\n",
      "Loss: 3.0722934365272523;\n",
      "Loss: 3.0758806693553926;\n",
      "Loss: 3.071316725254059;\n",
      "Loss: 3.0740885110696157;\n",
      "Loss: 3.0750972614969525;\n",
      "Loss: 3.0759762197732927;\n",
      "Loss: 3.0767301008436414;\n",
      "Loss: 3.078128836631775;\n",
      "Loss: 3.0785767711292613;\n",
      "Loss: 3.079378440777461;\n",
      "Loss: 3.078785439454592;\n",
      "Loss: 3.0786797060285296;\n",
      "Loss: 3.0809462087949115;\n",
      "Loss: 3.079479089528322;\n",
      "Loss: 3.0813213654125438;\n",
      "Loss: 3.0809310528967115;\n",
      "Loss: 3.0815218979433965;\n",
      "Loss: 3.0821862989664077;\n",
      "Loss: 3.0824168091728574;\n",
      "Loss: 3.0832822560180317;\n",
      "Loss: 3.0829690063518025;\n",
      "Loss: 3.0830519122878712;\n",
      "Loss: 3.0820710309982298;\n",
      "Loss: 3.0817887133818407;\n",
      "Loss: 3.0815847759776647;\n",
      "Loss: 3.0805759053570885;\n",
      "Loss: 3.080093318922766;\n",
      "Loss: 3.0800916908582052;\n",
      "Loss: 3.079782057577564;\n",
      "Loss: 3.0802490293979643;\n",
      "Loss: 3.0809055691054374;\n",
      "Loss: 3.0795951910579906;\n",
      "Loss: 3.0797074298177445;\n",
      "Loss: 3.0790747041172453;\n",
      "Loss: 3.0784304495115538;\n",
      "Loss: 3.0777388725782697;\n",
      "Loss: 3.0764188366669876;\n",
      "Loss: 3.075887712419033;\n",
      "Loss: 3.0750744974322437;\n",
      "Loss: 3.0750545923482804;\n",
      "Loss: 3.074749619683554;\n",
      "Loss: 3.0744300456480547;\n",
      "Loss: 3.0735231484837002;\n",
      "Loss: 3.0732432312550753;\n",
      "Loss: 3.073151627297097;\n",
      "Loss: 3.072539159903924;\n",
      "Loss: 3.07177241038303;\n",
      "Loss: 3.0714835436344146;\n",
      "Loss: 3.071116352969525;\n",
      "Loss: 3.0703237449664336;\n",
      "Loss: 3.06937949801391;\n",
      "Loss: 3.0687257382163295;\n",
      "Loss: 3.0684203962412746;\n",
      "Loss: 3.067924219582762;\n",
      "Loss: 3.0677529750790513;\n",
      "Loss: 3.0677745868419777;\n",
      "Loss: 3.0677897961260907;\n",
      "Loss: 3.066870039621989;\n",
      "Loss: 3.066108132503072;\n",
      "Loss: 3.0653417808009733;\n",
      "Loss: 3.0646548220089502;\n",
      "Loss: 3.0638528990745546;\n",
      "Loss: 3.0629046482673057;\n",
      "Loss: 3.0625657193588487;\n",
      "Loss: 3.0620648242822335;\n",
      "Loss: 3.060947414461304;\n",
      "Loss: 3.060952360595482;\n",
      "Loss: 3.060786099059241;\n",
      "Loss: 3.060375310468002;\n",
      "Loss: 3.0597671564751203;\n",
      "Loss: 3.0591208629738795;\n",
      "Loss: 3.0586168371986697;\n",
      "Loss: 3.0580705916404725;\n",
      "Loss: 3.057439411125685;\n",
      "Loss: 3.0569918613619618;\n",
      "Loss: 3.0561547653797345;\n",
      "Loss: 3.056106005409096;\n",
      "Loss: 3.0554455026686194;\n",
      "Loss: 3.054682137907287;\n",
      "Loss: 3.054276091063895;\n",
      "Loss: 3.0537944823000807;\n",
      "Loss: 3.0533400466328575;\n",
      "Loss: 3.052663789440604;\n",
      "Loss: 3.05221945410551;\n",
      "Loss: 3.051297802486639;\n",
      "Loss: 3.050617849962278;\n",
      "Loss: 3.0497775616270775;\n",
      "Loss: 3.0491383205519784;\n",
      "Loss: 3.048692423563737;\n",
      "Loss: 3.0477546969444855;\n",
      "Loss: 3.0471823688989046;\n",
      "Loss: 3.0465358895697494;\n",
      "Loss: 3.045900992217817;\n",
      "Improved from 3.080909373283386 to 2.8849547567367555, saving model..\n",
      "Epoch: 3, Train loss: 3.046, Val loss: 2.885,            Epoch time=1044.190s\n",
      "Hey !\n",
      "How ' s your business ?\n",
      "How ' s the wife ?\n",
      "You ' re still getting the French , right ?\n",
      "Loss: 2.873098227977753;\n",
      "Loss: 2.85950057387352;\n",
      "Loss: 2.8599691756566368;\n",
      "Loss: 2.854734736084938;\n",
      "Loss: 2.857868098735809;\n",
      "Loss: 2.8605061475435893;\n",
      "Loss: 2.8616199054036824;\n",
      "Loss: 2.862844024002552;\n",
      "Loss: 2.860665207174089;\n",
      "Loss: 2.860950224161148;\n",
      "Loss: 2.8637282553586094;\n",
      "Loss: 2.8642432089646657;\n",
      "Loss: 2.8655729809174173;\n",
      "Loss: 2.864993421350207;\n",
      "Loss: 2.865817372481028;\n",
      "Loss: 2.865884537398815;\n",
      "Loss: 2.865405114819022;\n",
      "Loss: 2.8669638212521873;\n",
      "Loss: 2.8679651951789857;\n",
      "Loss: 2.868979282259941;\n",
      "Loss: 2.8702228775478544;\n",
      "Loss: 2.870478966669603;\n",
      "Loss: 2.869828280262325;\n",
      "Loss: 2.870216810107231;\n",
      "Loss: 2.87082516002655;\n",
      "Loss: 2.8704128865095284;\n",
      "Loss: 2.871618742589597;\n",
      "Loss: 2.87140228841986;\n",
      "Loss: 2.8724216050115126;\n",
      "Loss: 2.8727148883342744;\n",
      "Loss: 2.8725590236725345;\n",
      "Loss: 2.8722566924244166;\n",
      "Loss: 2.8721542311437203;\n",
      "Loss: 2.872673275049995;\n",
      "Loss: 2.8728797609465464;\n",
      "Loss: 2.8728083855575983;\n",
      "Loss: 2.873333389179127;\n",
      "Loss: 2.873635089209205;\n",
      "Loss: 2.873420869692778;\n",
      "Loss: 2.873619360268116;\n",
      "Loss: 2.873247859885053;\n",
      "Loss: 2.873568723088219;\n",
      "Loss: 2.873618980285733;\n",
      "Loss: 2.8734433688900687;\n",
      "Loss: 2.8724842200809055;\n",
      "Loss: 2.872335501546445;\n",
      "Loss: 2.8720312009973727;\n",
      "Loss: 2.871715745081504;\n",
      "Loss: 2.871496372271557;\n",
      "Loss: 2.871137807846069;\n",
      "Loss: 2.8709749290989897;\n",
      "Loss: 2.8710321301680346;\n",
      "Loss: 2.8709232413094;\n",
      "Loss: 2.8705052885744307;\n",
      "Loss: 2.8703426014726814;\n",
      "Loss: 2.8696048635670115;\n",
      "Loss: 2.8698098791273017;\n",
      "Loss: 2.8694917831338684;\n",
      "Loss: 2.869411841368271;\n",
      "Loss: 2.86882707854112;\n",
      "Loss: 2.8682439127906423;\n",
      "Loss: 2.8679518993054667;\n",
      "Loss: 2.8673721989752754;\n",
      "Loss: 2.8667418240383267;\n",
      "Loss: 2.8668832635879515;\n",
      "Loss: 2.8670520023143653;\n",
      "Loss: 2.866785598406151;\n",
      "Loss: 2.8662202075299095;\n",
      "Loss: 2.8657454398749533;\n",
      "Loss: 2.865455570084708;\n",
      "Loss: 2.8651482640857426;\n",
      "Loss: 2.8647045146425567;\n",
      "Loss: 2.8644005255829796;\n",
      "Loss: 2.863968589595846;\n",
      "Loss: 2.8634745678901674;\n",
      "Loss: 2.8632095025401365;\n",
      "Loss: 2.8627710645849054;\n",
      "Loss: 2.8626782139142355;\n",
      "Loss: 2.8621559881258616;\n",
      "Loss: 2.8620586885511874;\n",
      "Loss: 2.861833360783848;\n",
      "Loss: 2.8614417992277845;\n",
      "Loss: 2.861197719688875;\n",
      "Loss: 2.860724195923124;\n",
      "Loss: 2.8601873811273015;\n",
      "Loss: 2.8596693096049997;\n",
      "Loss: 2.8595619757148043;\n",
      "Loss: 2.8592436525225637;\n",
      "Loss: 2.8586460928702624;\n",
      "Loss: 2.8585943746301865;\n",
      "Loss: 2.8581485819816588;\n",
      "Loss: 2.8578762980129406;\n",
      "Loss: 2.857533689750138;\n",
      "Loss: 2.857212564640857;\n",
      "Loss: 2.8567398943650093;\n",
      "Improved from 2.8849547567367555 to 2.739126233100891, saving model..\n",
      "Epoch: 4, Train loss: 2.857, Val loss: 2.739,            Epoch time=1044.452s\n",
      "Hello !\n",
      "How ' s your business ?\n",
      "How ' s the wife , how are kids ?\n",
      "You ' ll eat these soft French dishes ,\n",
      "Loss: 2.6616927790641784;\n",
      "Loss: 2.6697352206707;\n",
      "Loss: 2.6777223364512124;\n",
      "Loss: 2.6783397901058197;\n",
      "Loss: 2.6800559988021853;\n",
      "Loss: 2.678168129126231;\n",
      "Loss: 2.678415514741625;\n",
      "Loss: 2.683670564293861;\n",
      "Loss: 2.6848252524269953;\n",
      "Loss: 2.6893869256973266;\n",
      "Loss: 2.6892838007753546;\n",
      "Loss: 2.688908893465996;\n",
      "Loss: 2.690761084006383;\n",
      "Loss: 2.6923872905118125;\n",
      "Loss: 2.6935513377189637;\n",
      "Loss: 2.6953653691709043;\n",
      "Loss: 2.6977429813497205;\n",
      "Loss: 2.6995400234063465;\n",
      "Loss: 2.7020386747310035;\n",
      "Loss: 2.703388826608658;\n",
      "Loss: 2.704567535718282;\n",
      "Loss: 2.7055558890646156;\n",
      "Loss: 2.7064900925885076;\n",
      "Loss: 2.7057832514246303;\n",
      "Loss: 2.7060179114341736;\n",
      "Loss: 2.707828310544674;\n",
      "Loss: 2.708576743161237;\n",
      "Loss: 2.7091062581539154;\n",
      "Loss: 2.708632999124198;\n",
      "Loss: 2.709280122280121;\n",
      "Loss: 2.7096183400000293;\n",
      "Loss: 2.709962629750371;\n",
      "Loss: 2.7104671024553704;\n",
      "Loss: 2.71140513939016;\n",
      "Loss: 2.711601350579943;\n",
      "Loss: 2.7113980564806197;\n",
      "Loss: 2.7113494608853315;\n",
      "Loss: 2.7108143335894535;\n",
      "Loss: 2.711508865234179;\n",
      "Loss: 2.71135571706295;\n",
      "Loss: 2.71175544570132;\n",
      "Loss: 2.712180175610951;\n",
      "Loss: 2.7124680984297465;\n",
      "Loss: 2.7127870588410983;\n",
      "Loss: 2.712373906241523;\n",
      "Loss: 2.7121133181323174;\n",
      "Loss: 2.712070090161993;\n",
      "Loss: 2.712234882215659;\n",
      "Loss: 2.7122582615638264;\n",
      "Loss: 2.7118533482551577;\n",
      "Loss: 2.711420593074724;\n",
      "Loss: 2.711929374245497;\n",
      "Loss: 2.711714063005627;\n",
      "Loss: 2.7117236720632625;\n",
      "Loss: 2.711474870941856;\n",
      "Loss: 2.7114889517852236;\n",
      "Loss: 2.71166399043903;\n",
      "Loss: 2.711528165299317;\n",
      "Loss: 2.7111878532878424;\n",
      "Loss: 2.7110844735304513;\n",
      "Loss: 2.711017008374949;\n",
      "Loss: 2.7111707179777085;\n",
      "Loss: 2.711189824248117;\n",
      "Loss: 2.7109478440880777;\n",
      "Loss: 2.710510176548591;\n",
      "Loss: 2.71023871960062;\n",
      "Loss: 2.7102719420105665;\n",
      "Loss: 2.709751978341271;\n",
      "Loss: 2.709869469386944;\n",
      "Loss: 2.7098795400347027;\n",
      "Loss: 2.710158695200799;\n",
      "Loss: 2.7101427403092386;\n",
      "Loss: 2.710087317995829;\n",
      "Loss: 2.7101567907268937;\n",
      "Loss: 2.709863527329763;\n",
      "Loss: 2.7095433541661813;\n",
      "Loss: 2.7094525487701615;\n",
      "Loss: 2.7094506357266352;\n",
      "Loss: 2.709361394598514;\n",
      "Loss: 2.7095409392416476;\n",
      "Loss: 2.7095639037202908;\n",
      "Loss: 2.709421307866166;\n",
      "Loss: 2.709392459248922;\n",
      "Loss: 2.7092550224917273;\n",
      "Loss: 2.709143715353573;\n",
      "Loss: 2.7087070487820823;\n",
      "Loss: 2.7086243235653846;\n",
      "Loss: 2.7084799738634717;\n",
      "Loss: 2.7083220186930026;\n",
      "Loss: 2.7081870205137464;\n",
      "Loss: 2.7079410738997405;\n",
      "Loss: 2.707641375142595;\n",
      "Loss: 2.70745677035342;\n",
      "Loss: 2.7074017763137816;\n",
      "Loss: 2.707141788231699;\n",
      "Improved from 2.739126233100891 to 2.629872459888458, saving model..\n",
      "Epoch: 5, Train loss: 2.707, Val loss: 2.630,            Epoch time=1042.568s\n",
      "Hey !\n",
      "How are you ?\n",
      "How ' s the kids ?\n",
      "You ' ll eat these soft French fries , eat .\n",
      "Loss: 2.5667409777641295;\n",
      "Loss: 2.567356538772583;\n",
      "Loss: 2.5611025206247966;\n",
      "Loss: 2.56728904902935;\n",
      "Loss: 2.565786638736725;\n",
      "Loss: 2.56121001402537;\n",
      "Loss: 2.564223450933184;\n",
      "Loss: 2.562039965391159;\n",
      "Loss: 2.5632325249248082;\n",
      "Loss: 2.5646221816539763;\n",
      "Loss: 2.562658293030479;\n",
      "Loss: 2.562205350200335;\n",
      "Loss: 2.5628019622656013;\n",
      "Loss: 2.563665097270693;\n",
      "Loss: 2.5666349210739137;\n",
      "Loss: 2.5684529523551465;\n",
      "Loss: 2.569132253702949;\n",
      "Loss: 2.570467680030399;\n",
      "Loss: 2.5717238949474535;\n",
      "Loss: 2.572888694047928;\n",
      "Loss: 2.573614010470254;\n",
      "Loss: 2.5737100525335834;\n",
      "Loss: 2.5737574857214223;\n",
      "Loss: 2.5742727874716125;\n",
      "Loss: 2.576464880657196;\n",
      "Loss: 2.5765642641140865;\n",
      "Loss: 2.5784089891115824;\n",
      "Loss: 2.578970172405243;\n",
      "Loss: 2.579937909060511;\n",
      "Loss: 2.5806662112077077;\n",
      "Loss: 2.581882187551068;\n",
      "Loss: 2.582721902579069;\n",
      "Loss: 2.58223732659311;\n",
      "Loss: 2.5827229605702793;\n",
      "Loss: 2.582973195416587;\n",
      "Loss: 2.582705866826905;\n",
      "Loss: 2.582998847317051;\n",
      "Loss: 2.5826163899271113;\n",
      "Loss: 2.5829484682816726;\n",
      "Loss: 2.5831843227148057;\n",
      "Loss: 2.583038922344766;\n",
      "Loss: 2.583085717473711;\n",
      "Loss: 2.583143072738204;\n",
      "Loss: 2.5836119558052584;\n",
      "Loss: 2.583800581296285;\n",
      "Loss: 2.583723881089169;\n",
      "Loss: 2.5841013634458503;\n",
      "Loss: 2.584513270308574;\n",
      "Loss: 2.5842374183207144;\n",
      "Loss: 2.58408515086174;\n",
      "Loss: 2.5842213604496975;\n",
      "Loss: 2.5847531695549306;\n",
      "Loss: 2.5843120811570364;\n",
      "Loss: 2.584794164498647;\n",
      "Loss: 2.5845148331468755;\n",
      "Loss: 2.5846914645603727;\n",
      "Loss: 2.584776978492737;\n",
      "Loss: 2.584832797173796;\n",
      "Loss: 2.5842959536940366;\n",
      "Loss: 2.5844695670604705;\n",
      "Loss: 2.584309172591225;\n",
      "Loss: 2.584436675310135;\n",
      "Loss: 2.5842388815728445;\n",
      "Loss: 2.584097824729979;\n",
      "Loss: 2.5843596392044654;\n",
      "Loss: 2.584418649637338;\n",
      "Loss: 2.5843909492777355;\n",
      "Loss: 2.5843760396803126;\n",
      "Loss: 2.584260404282722;\n",
      "Loss: 2.5843857232502527;\n",
      "Loss: 2.5840232656035624;\n",
      "Loss: 2.5841798331671293;\n",
      "Loss: 2.5840952369284955;\n",
      "Loss: 2.5839994535252853;\n",
      "Loss: 2.5837881412823993;\n",
      "Loss: 2.5839780342578886;\n",
      "Loss: 2.5841652019921835;\n",
      "Loss: 2.584081320243004;\n",
      "Loss: 2.58368291465542;\n",
      "Loss: 2.583660653591156;\n",
      "Loss: 2.5837703479072194;\n",
      "Loss: 2.584144614586016;\n",
      "Loss: 2.5838634293050653;\n",
      "Loss: 2.583647075777962;\n",
      "Loss: 2.5836380667686463;\n",
      "Loss: 2.5836671509299167;\n",
      "Loss: 2.583681609192114;\n",
      "Loss: 2.583666798960079;\n",
      "Loss: 2.5833498588840613;\n",
      "Loss: 2.583348344431983;\n",
      "Loss: 2.583287248847249;\n",
      "Loss: 2.583104172659957;\n",
      "Loss: 2.583159175278038;\n",
      "Loss: 2.5830566046846672;\n",
      "Loss: 2.582954588614012;\n",
      "Improved from 2.629872459888458 to 2.5379053444862367, saving model..\n",
      "Epoch: 6, Train loss: 2.583, Val loss: 2.538,            Epoch time=1258.932s\n",
      "Hey !\n",
      "How you doing ?\n",
      "How ' s the wife like kids ?\n",
      "You eat these soft French bars , drink .\n",
      "Loss: 2.429168291091919;\n",
      "Loss: 2.43306223154068;\n",
      "Loss: 2.4339658419291177;\n",
      "Loss: 2.44305899143219;\n",
      "Loss: 2.4441625146865844;\n",
      "Loss: 2.4478764780362448;\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      7\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[0;32m----> 8\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m timer()\n\u001b[1;32m     10\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_generator, loss_fn, run)\n",
      "Cell \u001b[0;32mIn[32], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, iterator, optimizer, criterion, scheduler, run, print_every)\u001b[0m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 25\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m print_every:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(epoch_loss)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from timeit import default_timer as timer\n",
    "NUM_EPOCHS = 20\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    start_time = timer()\n",
    "    train_loss = train(model, training_generator, optimizer, loss_fn, scheduler, run)\n",
    "    end_time = timer()\n",
    "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
    "\n",
    "    if not losses:\n",
    "        print(f'First epoch - {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "\n",
    "    elif val_loss < min(losses):\n",
    "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
    "        torch.save(model, 'model')\n",
    "\n",
    "    losses.append(val_loss)\n",
    "\n",
    "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
    "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
    "\n",
    "    print(translate(\"Привет!\"))\n",
    "    print(translate('Как твои дела?'))\n",
    "    print(translate('Как жена, как дети?'))\n",
    "    print(translate('съешь же ещё этих мягких французских булок, да выпей чаю'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59335b8b",
   "metadata": {},
   "source": [
    "### Эпох на самом деле 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33addcae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_ ч 4 all the time asking Tyler M г\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:508: UserWarning: The PyTorch API of nested tensors is in prototype stage and will change in the near future. We recommend specifying layout=torch.jagged when constructing a nested tensor, as this layout receives active development, has better operator coverage, and works with torch.compile. (Triggered internally at /pytorch/aten/src/ATen/NestedTensorImpl.cpp:178.)\n",
      "  output = torch._nested_tensor_from_mask(\n"
     ]
    }
   ],
   "source": [
    "#  В этот момент он понял, что псё потерял ((\n",
    "print(translate('Меня всё время спрашивают: знаю ли я Тайлера Дёрдена?'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e0c3847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('./data/en-ru-test.ru').read().replace('\\xa0', ' ')\n",
    "f = open('./data/en-ru-test.ru', 'w')\n",
    "f.write(text)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "78b71254",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_sents = open('./data/en-ru-train.en').read().splitlines()[666:777]  #  <-- Тут теперь настоящие английские предложения\n",
    "ru_test_sents = open('./data/en-ru-train.ru').read().splitlines()[666:777]  #  <-- А тут русские"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "eb82c021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111, 111)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_test_sents), len(ru_test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f850d553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('These kids are killing me.', 'Эти дети меня убивают.')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_test_sents[13], ru_test_sents[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2689e62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = []\n",
    "\n",
    "for ru_, en_ in zip(ru_test_sents, en_test_sents):\n",
    "    translations.append(\n",
    "        {\n",
    "            \"inpt\": ru_,\n",
    "            \"fact\": translate(ru_),\n",
    "            \"expt\": en_,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7ec47ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': '- Да, хозяин.',\n",
       " 'fact': '- Yes , the owner .',\n",
       " 'expt': '- Yes, Master.'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53687f7a",
   "metadata": {},
   "source": [
    "#### Нужно очистить всё от пунктуации и оставить только слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8b83ae6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb2dab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc(string):\n",
    "    translator = string.maketrans(\"\", \"\", punctuation)\n",
    "    return string.translate(translator).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eca5ac15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(translations)):\n",
    "    thriplet = translations[i]\n",
    "    thriplet[\"fact\"] = preproc(thriplet[\"fact\"])\n",
    "    thriplet[\"expt\"] = preproc(thriplet[\"expt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7c646f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': '- Да, хозяин.', 'fact': 'Yes  the owner', 'expt': 'Yes Master'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9bf607ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': 'Эти дети меня убивают.',\n",
       " 'fact': 'These kids kill me',\n",
       " 'expt': 'These kids are killing me'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bfdf15b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8dd79c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(translations)):\n",
    "    thriplet = translations[i]\n",
    "    fact = thriplet[\"fact\"].lower().split()\n",
    "    expt = thriplet[\"expt\"].lower().split()\n",
    "    thriplet[\"bleu\"] = nltk.translate.bleu_score.sentence_bleu([fact], expt, auto_reweigh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd1f54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'inpt': 'Эти дети меня убивают.',\n",
       "  'fact': 'These kids kill me',\n",
       "  'expt': 'These kids are killing me',\n",
       "  'bleu': 9.283142785759642e-155},\n",
       " 111)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ddf3579b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inpt': 'Держитесь!', 'fact': 'Hold on', 'expt': 'Hold on', 'bleu': 1.0},\n",
       " {'inpt': 'Детка...', 'fact': 'Babe', 'expt': 'Babe', 'bleu': 1.0},\n",
       " {'inpt': 'Что случилось?',\n",
       "  'fact': 'What happened',\n",
       "  'expt': 'What happened',\n",
       "  'bleu': 1.0},\n",
       " {'inpt': 'Все чисто.', 'fact': 'All clear', 'expt': 'All clear', 'bleu': 1.0},\n",
       " {'inpt': 'Марси.', 'fact': 'Marcy', 'expt': 'Marcy', 'bleu': 1.0},\n",
       " {'inpt': 'И я тебя люблю.',\n",
       "  'fact': 'I love you',\n",
       "  'expt': 'I love you',\n",
       "  'bleu': 1.0},\n",
       " {'inpt': 'Хмм.', 'fact': 'Hmm', 'expt': 'Hmm', 'bleu': 1.0},\n",
       " {'inpt': 'Хочу выйти за тебя замуж!',\n",
       "  'fact': 'I want to marry you',\n",
       "  'expt': 'I want to marry you',\n",
       "  'bleu': 1.0},\n",
       " {'inpt': 'Алан Гарнер.',\n",
       "  'fact': 'Alan Garner',\n",
       "  'expt': 'Alan Garner',\n",
       "  'bleu': 1.0},\n",
       " {'inpt': 'Сомали', 'fact': 'Somalia', 'expt': 'Somalia', 'bleu': 1.0}]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(translations, key=lambda d: d[\"bleu\"], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410f97dd",
   "metadata": {},
   "source": [
    "### Переводы получились идеальные (с поправкой на пунктуацию и кейс букв) но предложения совсем маленькие. Можно попробовать попереводить что-то длинное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52207d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_test_sents = open('./data/en-ru-train.en').read().splitlines()  #  <-- Тут теперь настоящие английские предложения\n",
    "ru_test_sents = open('./data/en-ru-train.ru').read().splitlines()  #  <-- А тут русские"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fb206782",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_translate = []\n",
    "\n",
    "for i, sent in enumerate(ru_test_sents):\n",
    "    if len(sent) > 50:\n",
    "        to_translate.append(i)\n",
    "    if len(to_translate) == 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "bc5e0f2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(to_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "48475fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translations = []\n",
    "\n",
    "for i in to_translate:\n",
    "    ru_ = ru_test_sents[i]\n",
    "    en_ = en_test_sents[i]\n",
    "    translations.append(\n",
    "        {\n",
    "            \"inpt\": ru_,\n",
    "            \"fact\": preproc(translate(ru_)),\n",
    "            \"expt\": preproc(en_),\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4007896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': 'Разумеется, он преступник, но количество его жертв едва ли сравнимо с количеством жертв аварий на дорогах.',\n",
       " 'fact': 'Of course he  s a criminal  but the number of victims barely matched the victim',\n",
       " 'expt': 'He committed crimes but traffic causes many more victims than he does'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e92929e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/smertlove/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(translations)):\n",
    "    thriplet = translations[i]\n",
    "    fact = thriplet[\"fact\"].lower().split()\n",
    "    expt = thriplet[\"expt\"].lower().split()\n",
    "    thriplet[\"bleu\"] = nltk.translate.bleu_score.sentence_bleu([fact], expt, auto_reweigh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdbcb7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': 'Разумеется, он преступник, но количество его жертв едва ли сравнимо с количеством жертв аварий на дорогах.',\n",
       " 'fact': 'Of course he  s a criminal  but the number of victims barely matched the victim',\n",
       " 'expt': 'He committed crimes but traffic causes many more victims than he does',\n",
       " 'bleu': 1.0032743411283238e-231}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2af3abff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'inpt': 'Рассмотрение докладов, представленных государствами-участниками в соответствии со статьей 18 Конвенции (продолжение)',\n",
       "  'fact': 'Consideration of reports submitted by States parties under Article 18 of the Convention  continued',\n",
       "  'expt': 'Consideration of reports submitted by States parties under article 18 of the Convention continued',\n",
       "  'bleu': 1.0},\n",
       " {'inpt': 'Посмотрел, если у тебя шанс подумать насчет предложения.',\n",
       "  'fact': 'I mean  if you had a chance to think about the offer',\n",
       "  'expt': 'Seeing if you had a chance to think about the offer',\n",
       "  'bleu': 0.8155395405382073},\n",
       " {'inpt': 'У меня есть маленькая проблема с моей карточкой \" МаstеrCаrd\".',\n",
       "  'fact': 'I have a little problem with my card  Magog  tab',\n",
       "  'expt': 'I have a little problem with my MasterCard',\n",
       "  'bleu': 0.6548907866815301},\n",
       " {'inpt': 'В соответствии с обычной практикой я предлагаю, с согласия Совета, пригласить этого представителя для участия в дискуссии без права голоса, согласно соответствующим положениями Устава и правилу 37 временных правил процедуры Совета.',\n",
       "  'fact': 'In accordance with the usual practice  I propose  with the consent of the Council  invite the representative to participate in the discussion without the vote  to the relevant provisions of the Charter and Provisional Institutions 37 of the provisional rules of procedure of the',\n",
       "  'expt': 'In conformity with the usual practice I propose with the consent of the Council to invite that representative to participate in the discussion without the right to vote in accordance with the relevant provisions of the Charter and rule 37 of the Councils provisional rules of procedure',\n",
       "  'bleu': 0.619052085701245},\n",
       " {'inpt': 'This calendar view maps the number of times http://tremulous.net/forum/index.php?topic=15160.msg217808 was crawled by the Wayback Machine, not how many times the site was actually updated.',\n",
       "  'fact': 'This calendar view maps the number of times http  tremulous  net  forum  index  php  action  profile  u  16308 was crawled by the Wayback Machine  not how many times the site was actually updated',\n",
       "  'expt': 'This calendar view maps the number of times httptremulousnetforumindexphpactionprofileu26886 was crawled by the Wayback Machine not how many times the site was actually updated',\n",
       "  'bleu': 0.6078294233246405},\n",
       " {'inpt': 'This calendar view maps the number of times http://tremulous.net/forum/index.php?topic=12879.msg214428 was crawled by the Wayback Machine, not how many times the site was actually updated.',\n",
       "  'fact': 'This calendar view maps the number of times http  tremulous  net  forum  index  php  action  profile  u  16297 was crawled by the Wayback Machine  not how many times the site was actually updated',\n",
       "  'expt': 'This calendar view maps the number of times httptremulousnetforumindexphptopic146170 was crawled by the Wayback Machine not how many times the site was actually updated',\n",
       "  'bleu': 0.6078294233246405},\n",
       " {'inpt': 'Генеральная Ассамблея в своей резолюции 55/233 от 23 декабря 2000 года постановила, что в предлагаемом бюджете по программам на двухгодичный период 2002-2003 годов должны быть отражены ассигнования на финансирование специальных политических миссий, связанных с вопросами мира и безопасности.',\n",
       "  'fact': 'The General Assembly  in its resolution 55  233 of 23 December 2000  agreed that the proposed programme budget for the biennium 2002  2003 should be offset by the allocation of special political missions  with peace and security',\n",
       "  'expt': 'The General Assembly in its resolution 55233 of 23 December 2000 decided that a provision of 93691600 should be reflected in the proposed programme budget for the biennium 20022003 for special political missions related to peace and security',\n",
       "  'bleu': 0.41658028201971575},\n",
       " {'inpt': '18. осуждает злоупотребление средствами печатной, аудиовизуальной и электронной информации и новыми коммуникационными технологиями, в том числе Интернетом, в целях подстрекательства к насилию, мотивированному расовой ненавистью;',\n",
       "  'fact': '18  Condemns the abuse of print  visual communication and e  communication technologies  including the Internet to incite violence against the violence of racial violence',\n",
       "  'expt': '18 Condemns the misuse of print audiovisual and electronic media and new communication technologies including the Internet to incite violence motivated by racial hatred',\n",
       "  'bleu': 0.378786561257948},\n",
       " {'inpt': 'принимая к сведению доклады Генерального секретаря,',\n",
       "  'fact': 'Taking into account the reports of the Secretary  General',\n",
       "  'expt': 'Taking note of the reports of the SecretaryGeneral',\n",
       "  'bleu': 0.32260135189272865},\n",
       " {'inpt': 'Приоритетной потребностью министерства высшего образования по-прежнему является закупка компьютеров и специализированного оборудования, включая различные виды лабораторных наборов.',\n",
       "  'fact': 'The priority of the Ministry of Education remains the primary education and specialized equipment  including the various types of laboratory',\n",
       "  'expt': 'The priority need for the Ministry of Higher Education remains the procurement of computers and specialized equipment including various types of laboratory sets',\n",
       "  'bleu': 0.320557366345532}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(translations, key=lambda d: d[\"bleu\"], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d409c",
   "metadata": {},
   "source": [
    "### Тут всё уже не так гладко."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fa2e37b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'inpt': 'И у нас остаётся лишь несколько вариантов развития событий.',\n",
       " 'fact': 'We have just a few development options',\n",
       " 'expt': 'Leaves us with a couple possibilities',\n",
       " 'bleu': 9.853445011990208e-232}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translations[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727412b2",
   "metadata": {},
   "source": [
    "### Теперь можно доработать translate\n",
    "#### Для начала замерим старую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9a48040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_translate = ru_test_sents[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fa870ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(to_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c42d7e33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Он призывает государство-участник при осуществлении таких усилий в полной мере использовать общую рекомендацию 19 Комитета и Углубленное исследование Генерального секретаря Организации Объединенных Наций, посвященное всем формам насилия в отношении женщин (A/61/122/Add.1 и Corr.1).'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(to_translate, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "75842951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13min 28s, sys: 108 ms, total: 13min 28s\n",
      "Wall time: 58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    for sent in to_translate:\n",
    "        translate(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1de917a",
   "metadata": {},
   "source": [
    "#### Теперь можно попробовать пооптимизировать"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb14b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad\n",
    "def batch_translate(texts):\n",
    "\n",
    "\n",
    "    input_ids = [\n",
    "        tokenizer_en.encode(text).ids[:max_len_en]\n",
    "        for text in texts\n",
    "    ]\n",
    "\n",
    "    output_ids = [\n",
    "        [tokenizer_ru.token_to_id('[BOS]')]\n",
    "        for text\n",
    "        in texts\n",
    "    ]\n",
    "\n",
    "    input_ids_pads = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(ids) for ids in input_ids],\n",
    "        batch_first=True\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    output_ids_pads = torch.nn.utils.rnn.pad_sequence(\n",
    "        [torch.LongTensor(ids) for ids in output_ids],\n",
    "        batch_first=True\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    src_padding_mask = (input_ids_pads == PAD_IDX).to(DEVICE)\n",
    "    tgt_padding_mask = (output_ids_pads == PAD_IDX).to(DEVICE)\n",
    "\n",
    "    # Идея в том, чтобы на каждом витке вопхать в модель сразу весь многомерный тензор и потом посмотреть, какие предложения закончились\n",
    "    finished = [False for _ in range(len(texts))]\n",
    "    logits = model(input_ids_pads, output_ids_pads, src_padding_mask, tgt_padding_mask)\n",
    "    preds = logits.argmax(2)\n",
    "\n",
    "    while len(max(output_ids)) < 100 and not all(finished):\n",
    "        for i in range(len(finished)):\n",
    "            if not finished[i]:\n",
    "                item = preds[i].item()\n",
    "                if item in {tokenizer_ru.token_to_id('[EOS]'), tokenizer_ru.token_to_id('[PAD]')}:\n",
    "                    finished[i] = True\n",
    "                else:\n",
    "                    output_ids[i].append(item)\n",
    "\n",
    "        output_ids_pads = torch.nn.utils.rnn.pad_sequence(\n",
    "            [torch.LongTensor(ids) for ids in output_ids],\n",
    "            batch_first=True\n",
    "        ).to(DEVICE)\n",
    "        tgt_padding_mask = (output_ids_pads == PAD_IDX).to(DEVICE)\n",
    "\n",
    "        logits = model(input_ids_pads, output_ids_pads, src_padding_mask, tgt_padding_mask)\n",
    "        preds = logits[:, -1, :].argmax(1)  # <-- я не понимаю почему это работает\n",
    "\n",
    "    return [\n",
    "        tokenizer_ru.decoder.decode(\n",
    "            [\n",
    "                tokenizer_ru.id_to_token(i)\n",
    "                for i\n",
    "                in ids[1:]\n",
    "            ]\n",
    "        )\n",
    "        for ids\n",
    "        in output_ids\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7b944f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Я вижу всех этих уродов лгущих тебе.\tI can see all these guys .\n",
      "Ты сказал Дену, что я здесь был?\tDid you say that I was here ?\n",
      "Большинству ваших людей придется остаться на кораблях.\tThe man you ' re gonna have to stay with the ship .\n",
      "Потому, прямо сейчас.\tBecause right now .\n",
      "И ему понравится то, что мы приготовили.\tHe ' s gonna like what we have .\n",
      "Всё что у меня есть.\tI ' m all I have .\n",
      "Нет, нет, нет.\tNo , no , no .\n",
      "Липа.\tLip .\n",
      "- Что там дальше?\t- What ' s next ?\n",
      "Держи меня за руку.\tKeep my hand .\n"
     ]
    }
   ],
   "source": [
    "for ru_, en_ in zip(to_translate[10:20], batch_translate(to_translate[10:20])):\n",
    "    print(ru_, en_, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7e3a5fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 33s, sys: 54.9 ms, total: 1min 34s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in range(10):\n",
    "    batch_translate(to_translate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "12d9ac1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.37037037037037"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "58 / 10.8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048af612",
   "metadata": {},
   "source": [
    "### В 5 с лишним раз ускорились\n",
    "Теперь нужно перевести весь трейнинг датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "faf1bdab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000000, 1000000)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ru_test_sents), len(en_test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4b16a61c",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 7.66 GiB of which 100.81 MiB is free. Including non-PyTorch memory, this process has 7.54 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 560.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:8\u001b[0m\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[185], line 49\u001b[0m, in \u001b[0;36mbatch_translate\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m     43\u001b[0m     output_ids_pads \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mrnn\u001b[38;5;241m.\u001b[39mpad_sequence(\n\u001b[1;32m     44\u001b[0m         [torch\u001b[38;5;241m.\u001b[39mLongTensor(ids) \u001b[38;5;28;01mfor\u001b[39;00m ids \u001b[38;5;129;01min\u001b[39;00m output_ids],\n\u001b[1;32m     45\u001b[0m         batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     )\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     47\u001b[0m     tgt_padding_mask \u001b[38;5;241m=\u001b[39m (output_ids_pads \u001b[38;5;241m==\u001b[39m PAD_IDX)\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[0;32m---> 49\u001b[0m     logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids_pads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_ids_pads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_padding_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_padding_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     preds \u001b[38;5;241m=\u001b[39m logits[:, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# <-- я не понимаю почему это работает\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[1;32m     53\u001b[0m     tokenizer_ru\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mdecode(\n\u001b[1;32m     54\u001b[0m         [\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;129;01min\u001b[39;00m output_ids\n\u001b[1;32m     62\u001b[0m ]\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[21], line 48\u001b[0m, in \u001b[0;36mTransformerEncoderDecoder.forward\u001b[0;34m(self, src, tgt, src_key_padding_mask, tgt_key_padding_mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m encoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m     36\u001b[0m     src_embedded,\n\u001b[1;32m     37\u001b[0m     src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask\n\u001b[1;32m     38\u001b[0m )\n\u001b[1;32m     40\u001b[0m decoder_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer\u001b[38;5;241m.\u001b[39mdecoder(\n\u001b[1;32m     41\u001b[0m     tgt_embedded,\n\u001b[1;32m     42\u001b[0m     encoder_output,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     memory_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask\n\u001b[1;32m     46\u001b[0m )\n\u001b[0;32m---> 48\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/sandbox/hse/nlp_hw/compling_nlp_hw/.venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 196.00 MiB. GPU 0 has a total capacity of 7.66 GiB of which 100.81 MiB is free. Including non-PyTorch memory, this process has 7.54 GiB memory in use. Of the allocated memory 6.83 GiB is allocated by PyTorch, and 560.47 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "translations = []\n",
    "batchsize = 100\n",
    "\n",
    "for i in range(0, len(ru_test_sents), batchsize):\n",
    "    j = i + batchsize\n",
    "\n",
    "    translations.extend(\n",
    "        batch_translate(ru_test_sents[i:j])\n",
    "    )\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4493cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6674412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "9403583f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Mar 20 03:48:59 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 555.42.06              Driver Version: 555.42.06      CUDA Version: 12.5     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    Off |   00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   45C    P3             12W /   65W |    7743MiB /   8188MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      4032      G   /usr/lib/xorg/Xorg                              4MiB |\n",
      "|    0   N/A  N/A     10198      C   ...hw/compling_nlp_hw/.venv/bin/python       7720MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2aacfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c7fafc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e9eb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f36a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5aa93d6",
   "metadata": {},
   "source": [
    "\n",
    "## Задание 2 (2 балла).\n",
    "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
    "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
    "\n",
    "Ответ должен содержать как минимум 10 предложений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5bf2f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82543fd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
